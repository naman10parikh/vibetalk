# üéôÔ∏è Vibe Talk - Development Task List

## üéØ Current Goal
Build a background service that lets you speak to localhost and auto-inject transcribed text into Cursor's Composer.

## üìã Task Status
- ‚úÖ Completed
- üîÑ In Progress  
- ‚è≥ Next Up
- üìù Planned

---

## Phase 1: Research & Architecture ‚è≥

### 1.1 Research Cursor Integration
- ‚úÖ Research how Cursor extensions work (VSCode-based?)
- ‚úÖ Investigate Cursor Composer API/automation possibilities
- ‚úÖ Test if Cursor can be automated via AppleScript/Accessibility APIs (macOS)
- ‚úÖ Explore VS Code extension APIs that might work with Cursor

### 1.2 Architecture Decision
- ‚úÖ Decide between: VSCode Extension vs Background Service vs Hybrid
- ‚úÖ Choose text injection method (API vs system automation)
- ‚úÖ Finalize tech stack based on research

**DECISION: Background Service + AppleScript Automation**
- Background Node.js service for audio recording and Whisper API
- AppleScript for text injection into Cursor Composer
- Global hotkeys for activation

---

## Phase 2: Core Infrastructure ‚úÖ

### 2.1 Project Setup
- ‚úÖ Set up TypeScript configuration
- ‚úÖ Create basic folder structure
- ‚úÖ Install and configure dependencies
- ‚úÖ Set up development scripts

### 2.2 Audio Recording System
- ‚úÖ Implement basic audio recording (Node.js)
- ‚úÖ Test microphone access and permissions 
- ‚úÖ Create audio file handling (temp files)
- ‚úÖ Add recording controls (start/stop)

### 2.3 Background Service
- ‚è≥ Create Node.js background service
- ‚è≥ Implement global hotkey detection
- ‚è≥ Add system tray/menu bar integration (macOS)
- ‚è≥ Test service startup and shutdown

---

## Phase 3: Speech-to-Text Integration üìù

### 3.1 OpenAI Whisper Setup
- ‚è≥ Set up OpenAI API integration
- ‚è≥ Implement audio file transcription
- ‚è≥ Add error handling for API calls
- ‚è≥ Test transcription accuracy

### 3.2 Audio Processing
- ‚è≥ Optimize audio format for Whisper
- ‚è≥ Add audio preprocessing (noise reduction?)
- ‚è≥ Implement chunking for long recordings
- ‚è≥ Add transcription caching

---

## Phase 4: Cursor Integration üìù

### 4.1 Text Injection Research
- ‚è≥ Test Cursor automation methods
- ‚è≥ Implement text injection mechanism
- ‚è≥ Add Cursor window detection
- ‚è≥ Test injection into Composer specifically

### 4.2 Workflow Integration
- ‚è≥ Implement complete voice ‚Üí text ‚Üí inject flow
- ‚è≥ Add status notifications
- ‚è≥ Test end-to-end workflow
- ‚è≥ Add error recovery

---

## Phase 5: User Experience üìù

### 5.1 Configuration
- ‚è≥ Create config file system
- ‚è≥ Add OpenAI API key management
- ‚è≥ Implement hotkey customization
- ‚è≥ Add settings UI (simple CLI or web interface)

### 5.2 Polish
- ‚è≥ Add loading indicators
- ‚è≥ Implement proper error messages
- ‚è≥ Add audio feedback (beeps, etc.)
- ‚è≥ Create simple documentation

---

## Phase 6: Testing & Deployment üìù

### 6.1 Testing
- ‚è≥ Create test scripts
- ‚è≥ Test on clean macOS environment
- ‚è≥ Performance testing (latency measurements)
- ‚è≥ Edge case testing (no internet, wrong API key, etc.)

### 6.2 Distribution
- ‚è≥ Create installation script
- ‚è≥ Package as macOS app/service
- ‚è≥ Write user documentation
- ‚è≥ Create demo video

---

## üöÄ MVP Definition

**Minimum Viable Product:**
1. Background service runs on macOS
2. Global hotkey (e.g., Cmd+Shift+V) starts recording
3. Audio gets transcribed via OpenAI Whisper
4. Transcribed text gets injected into active Cursor Composer
5. Simple configuration for API key

**Success Criteria:**
- ‚è≥ Record 10-second voice message
- ‚è≥ Transcribe with >90% accuracy
- ‚è≥ Inject into Cursor in <5 seconds total
- ‚è≥ Works without touching keyboard/mouse after hotkey

---

## üîß Technical Decisions Made

### Architecture: Background Service + System Automation
- **Why:** User wants global access, not just in-IDE interaction
- **How:** Node.js service + macOS Accessibility APIs or AppleScript

### Technology Stack:
- **Backend:** Node.js + TypeScript
- **Audio:** node-mic or similar for recording
- **Speech-to-Text:** OpenAI Whisper API
- **System Integration:** macOS Accessibility API or AppleScript
- **Hotkeys:** Global hotkey library (electron-globalshortcut or similar)

---

## üìù Notes & Ideas

- Consider adding wake word support later
- Maybe add support for other editors (VS Code, etc.) in future
- Could add voice commands like "submit this", "clear composer"
- Potential for offline Whisper model for privacy

---

**Last Updated:** Initial creation
**Next Priority:** Research Cursor integration methods 